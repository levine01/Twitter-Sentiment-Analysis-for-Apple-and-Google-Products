{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Collection and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "import xgboost as xgb\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  \\\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at   \n",
       "0                          iPhone  \\\n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset and preview first five rows\n",
    "data = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='ISO-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      " #   Column                                              Non-Null Count  Dtype \n",
      "---  ------                                              --------------  ----- \n",
      " 0   tweet_text                                          9092 non-null   object\n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object\n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9093 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# getting information of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_there_an_emotion_directed_at_a_brand_or_product\n",
      "No emotion toward brand or product    5389\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate sentiment counts\n",
    "sentiment_counts = data['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "print(sentiment_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the value count it's evident that the majority of people who tweeted either do not express any specific emotion towards a brand or product, while a relatively small number of tweets fall into categories where the sentiment (positive or negative) is not clearly discernible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine text data\n",
    "data['tweet_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning\n",
    "\n",
    "- Dropping unwanted columns\n",
    "- Handling missing values.\n",
    "- Clean text data by removing special characters, URLs, and hashtags.\n",
    "- Convert text to lowercase to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Dropping unwanted columns and 'i cant tell' category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping emotion_in_tweet_is_directed_at column since we wont be using it modelling\n",
    "columns_to_drop = ['emotion_in_tweet_is_directed_at']\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column has been dropped \n",
    "data.head()\n",
    "# 'the emotion in tweet is directed at' column has been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'i cant tell' and No emotion toward brand or product' category since we will only be using the two sentiments.\n",
    "data = data[(data['is_there_an_emotion_directed_at_a_brand_or_product'] != \"I can't tell\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if 'i cant tell' category has been dropped and 'No emotion toward brand or product' has been replaced\n",
    "data.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have performed data preprocessing by removing the 'emotion_in_tweet_is_directed_at' column, leaving us with two columns for further analysis. Additionally, we have excluded the 'I can't tell' category from the 'emotion' column, resulting in our dataset containing only the 'Positive,' 'Negative,' and 'No emotion toward brand or product' sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Handling mising values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if our dataset has missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the row with missing values\n",
    "# since we cannot impute text\n",
    "data = data.dropna(subset=['tweet_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking if the row with missing values has been dropped\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the tweet_text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3 Renaming columns and sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming'is_there_an_emotion_directed_at_a_brand_or_product'column to emotion to make it easy to work with\n",
    "data.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previewing the first five rows to check if the column has been renamed.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming 'No emotion toward a brand a brand or product' as neutral for easy analysis\n",
    "data['emotion'] = data['emotion'].replace({'No emotion toward brand or product': 'Neutral'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have simplified our analysis by renaming the 'is_there_an_emotion_directed_at_a_brand_or_product' column to 'emotion' and relabeling 'No emotion toward brand or product' as 'neutral' for clarity and ease of interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3 Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Ensure text is a string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove hashtags (including the # symbol)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters and punctuation (except spaces)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "   \n",
    "     #Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "# Function to apply lemmatization\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Apply text cleaning to the \"tweet_text\" column\n",
    "data['cleaned_tweet'] = data['tweet_text'].apply(clean_text)\n",
    "\n",
    "# Tokenize the \"tweet_text\" column\n",
    "data['tokenized_tweet'] = data['cleaned_tweet'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Apply lemmatization to the tokenized text\n",
    "data['lemmatized_tweet'] = data['tokenized_tweet'].apply(lemmatize_text)\n",
    "\n",
    "# Display the DataFrame with cleaned, tokenized, and lemmatized text\n",
    "print(data[['tweet_text', 'cleaned_tweet', 'tokenized_tweet', 'lemmatized_tweet']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization serves to break text into smaller units or tokens, making the text more manageable for analysis. Lemmatization reduces words to their base forms, enhancing standardization and simplification of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Join the tokenized tweets into a single string with space as a separator\n",
    "data['lemmatized_tweet'] = data['lemmatized_tweet'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Fit and transform your tokenized text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['lemmatized_tweet'])\n",
    "\n",
    "# The tfidf_matrix contains the TF-IDF vectors for the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code prepares and transforms the text data into a numerical format that can be used for sentimental analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Distribution of Sentiment Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame 'data' with a 'sentiment' column\n",
    "sentiment_counts = data['emotion'].value_counts()\n",
    "print(sentiment_counts)\n",
    "\n",
    "# Create a bar chart to visualize sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, color=['green', 'red', 'blue'])\n",
    "plt.xlabel('Sentiment Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Emotion Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization it's evident that the majority of people who tweeted either do not express any specific emotion towards a brand or product, while a relatively small number of tweets fall into categories where the sentiment (positive or negative) is not clearly discernible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Word Clouds for Each Sentiment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generating word count using word cloud and getting the visualization\n",
    "# Separate the dataset into positive, negative, neutral, and can't tell tweets\n",
    "pos_tweets = data[data['emotion'] == 'Positive emotion']['lemmatized_tweet']\n",
    "neg_tweets = data[data['emotion'] == 'Negative emotion']['lemmatized_tweet']\n",
    "\n",
    "# Filter and clean the 'neutral' tweets, handling any non-string values \n",
    "neut_tweets = data[data['emotion'] == \"Neutral\"]['lemmatized_tweet']\n",
    "#neut_tweets = neut_tweets.dropna().astype(str)  # Convert to string and drop NaN values\n",
    "# Create a 2x2 grid of subplots for word clouds\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Function to create and display a word cloud in a specific subplot\n",
    "def generate_word_cloud_subplot(text, title, position):\n",
    "    wordcloud = WordCloud(width=500, height=450, background_color='white', random_state=42).generate(text)\n",
    "    \n",
    "    plt.subplot(1,3, position)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Create word clouds for each sentiment category in specific subplots\n",
    "generate_word_cloud_subplot(' '.join(pos_tweets), 'Positive Tweets Word Cloud', 1)\n",
    "generate_word_cloud_subplot(' '.join(neg_tweets), 'Negative Tweets Word Cloud', 2)\n",
    "generate_word_cloud_subplot(' '.join(neut_tweets), 'Neutral Tweets Word Cloud', 3)\n",
    "\n",
    "plt.tight_layout()  # Ensures that subplots are properly arranged\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of  tweet lengths per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the tweet lengths under each category\n",
    "# Filter tweets by sentiment category\n",
    "positive_tweets = data[data['emotion'] == 'Positive emotion']['lemmatized_tweet']\n",
    "negative_tweets = data[data['emotion'] == 'Negative emotion']['lemmatized_tweet']\n",
    "neutral_tweets = data[data['emotion'] == 'Neutral']['lemmatized_tweet']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "# Function to plot tweet length histograms\n",
    "def plot_tweet_length_histograms(tweets, sentiment_label, ax):\n",
    "    tweet_lengths = tweets.str.len()\n",
    "    \n",
    "    ax.hist(tweet_lengths, bins=30, color='skyblue', edgecolor='black')\n",
    "    ax.set_xlabel('Tweet Length')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Tweet Length Distribution ({sentiment_label} Sentiment)')\n",
    "    ax.grid(True)\n",
    "\n",
    "# Plot histograms for each sentiment category\n",
    "plot_tweet_length_histograms(positive_tweets, 'Positive', axes[0])\n",
    "plot_tweet_length_histograms(negative_tweets, 'Negative', axes[1])\n",
    "plot_tweet_length_histograms(neutral_tweets, 'Neutral', axes[2])\n",
    "\n",
    "# Adjust subplots for tight layout\n",
    "plt.subplots_adjust(wspace=0.4)  # Adjust the horizontal space between subplots\n",
    "plt.tight_layout()  # Ensures a tight layout\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above reveals that, in terms of tweet length, neutral tweets are the longest, followed by positive tweets and then negative tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Binary classification\n",
    "We begin with binary classification, focusing on negative and positive emotions. We later extend the task to multiclass classification by adding a neutral class. The process involves the following steps:\n",
    "\n",
    "Data Splitting - We split the filtered data into training and testing sets using the train_test_split function.\n",
    "\n",
    "Label Encoding - To work with text labels, we encode 'emotion' labels ('Positive emotion' and 'Negative emotion') into numerical values ('Positive' as 1 and 'Negative' as 0) using LabelEncoder.\n",
    "\n",
    "TF-IDF Vectorization - We utilize TF-IDF vectorization to convert the text data into numerical vectors. The TfidfVectorizer is employed to represent each tweet as a vector of TF-IDF features.\n",
    "\n",
    "We assess the model's performance through accuracy calculation, a classification report containing precision, recall, and F1-score, and a confusion matrix, providing insights into its performance on individual classes.\n",
    "\n",
    "The modeling techniques we will use include naive bayes model, fine-tuning the Naive Bayes model and utilizing Support Vector Classification (SVC) to further enhance our sentiment analysis task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.1 Baseline Model using Naive Bayes\n",
    "\n",
    "Naive Bayes is selected as the baseline model for its simplicity, computational efficiency, and strong suitability for text classification tasks. Its straightforward nature allows for easy interpretation, making it an ideal starting point for modeling. Additionally, Naive Bayes provides a reasonable baseline performance, offering insights into achievable accuracy without the need for complex algorithms. This will also serve as a benchmark, helping assess whether more advanced models are justified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object to make sure 0 represents negative and 1 positive\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "#  fit the encoder\n",
    "custom_encoding = ['Negative', 'Positive']\n",
    "label_encoder.fit(custom_encoding)\n",
    "\n",
    "# Check the encoding mapping\n",
    "encoded_classes = label_encoder.classes_\n",
    "\n",
    "# Print the mapping\n",
    "print(\"Encoded Classes:\")\n",
    "for code, sentiment in enumerate(encoded_classes):\n",
    "    print(f\"Code {code} represents '{sentiment}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Filter the data to include only 'Positive' and 'Negative' labels\n",
    "filtered_data = data[(data['emotion'] == 'Positive emotion') | (data['emotion'] == 'Negative emotion')]\n",
    "\n",
    "# Split the filtered data into features (X) and labels (y)\n",
    "X = filtered_data['lemmatized_tweet']  # Features\n",
    "y = filtered_data['emotion']          # Labels (contains 'Positive' and 'Negative' classes)\n",
    "\n",
    "# Encode labels to numerical values (Positive: 1, Negative: 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well getting an accuracy of 84.2%  and correctly identifying 'Positive' tweets with high precision and recall, resulting in a high F1-score for class 1. However, it struggles to identify 'Negative' tweets, as indicated by the very low recall for class 0. The overall accuracy is somewhat inflated due to the class imbalance, where 'Positive' tweets dominate the dataset. Improving recall for class 0 may be a priority if better identification of 'Negative' sentiment is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.3  Model Iteration 1: Support Vector Machine (SVM)\n",
    "\n",
    "We transition to SVM to address the limitations observed in the Naive Bayes baseline model. SVMs are known for their versatility in handling imbalanced datasets, which is a challenge in our dataset where 'Positive' tweets dominate. Additionally, SVMs offer the potential to enhance recall for class 0 (negative sentiment) while maintaining high precision and recall for class 1 (positive sentiment), thereby mitigating the initial model's struggles with identifying negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Count Vectorizers for text data\n",
    "count_vectorizer = CountVectorizer(max_features=5000)\n",
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVM classifier with Count Vectors\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_train_count, y_train)\n",
    "\n",
    "# Make predictions on the test set using Count Vectors\n",
    "y_pred_count = svm_classifier.predict(X_test_count)\n",
    "\n",
    "# Calculate accuracy with Count Vectors\n",
    "accuracy_count = accuracy_score(y_test, y_pred_count)\n",
    "print(\"SVM Accuracy with Count Vectors:\", accuracy_count)\n",
    "\n",
    "# Display classification report with Count Vectors\n",
    "print(\"Classification Report with Count Vectors:\")\n",
    "print(classification_report(y_test, y_pred_count))\n",
    "\n",
    "# Display confusion matrix with Count Vectors\n",
    "print(\"Confusion Matrix with Count Vectors:\")\n",
    "print(confusion_matrix(y_test, y_pred_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) classifier achieved an accuracy of approximately 86.2% on a binary classification task. The model exhibits good performance in correctly predicting class 1 with high precision and recall, resulting in a high F1-score for class 1. However, similar to the previous Naive Bayes model, it faces challenges in identifying class 0 instances, leading to lower precision, recall, and F1-score for class 0. The overall weighted average F1-score indicates a reasonably good overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest\n",
    "\n",
    "To further improve the accuracy and address the challenges in identifying class 0 instances (negative sentiment), we consider using a Random Forest classifier as the next model. Random Forests are known for their ability to handle imbalanced datasets and perform well in text classification tasks. They often exhibit robustness in capturing complex patterns and relationships in the data, which can help enhance the classification of negative sentiment tweets. Additionally, Random Forests allow you to experiment with different hyperparameters, such as the number of estimators and maximum depth, to fine-tune the model's performance. This model choice, combined with hyperparameter tuning, can potentially yield improvements in accuracy and overall model performance for both class 0 and class 1 sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectors for text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "n_estimators = 100  # You can adjust the number of estimators (trees)\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "random_forest_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_forest_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model has an improved accuracy of approximately 87.32% on the dataset, indicating its overall effectiveness in classifying sentiment. The precision for identifying negative sentiment tweets is notably high at 90%, signifying that when the model predicts a tweet as negative, it is usually correct. However, the recall for negative sentiment is lower at 24%, implying that the model misses a significant proportion of negative tweets. In contrast, the model performs exceptionally well in identifying positive sentiment tweets, with a precision of 87% and near-perfect recall of 99%. These results are reflected in the F1-scores, where the model achieves an F1-score of 0.38 for negative sentiment and an impressive 0.93 for positive sentiment. The macro-average F1-score is 0.66, considering both sentiments, while the weighted-average F1-score, accounting for class imbalance, is 0.84. In the confusion matrix, the model correctly identifies a substantial number of true positives for positive sentiment but has a significant number of false negatives for negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model stands out as the best binary classification model among those assessed for sentiment analysis in this study. With an accuracy of approximately 87.32%, it outperforms both Naive Bayes and SVM with Count Vectors. The model exhibits a balanced performance, achieving a precision of 90% for negative sentiment and a remarkable 99% recall for positive sentiment. This balance is reflected in its F1-scores, which are 0.38 for negative sentiment and 0.93 for positive sentiment, surpassing the other models. Additionally, in the confusion matrix, the Random Forest model minimizes false negatives for negative sentiment, correctly classifying 28 true negatives and having only 3 false negatives. Overall, its strong accuracy, precision, recall, and F1-scores for both sentiment classes establish it as the most effective binary classification model for sentiment analysis in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Multiclass classification\n",
    "\n",
    "In this section, we will perform multiclass classification, working with three different sentiments. We will follow a similar process as we did for binary classification, with some modifications to accommodate the additional sentiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'emotion' column to encode sentiments\n",
    "data['emotion_encoded'] = label_encoder.fit_transform(data['emotion'])\n",
    "\n",
    "# Get the mapping of encoded values to original labels\n",
    "encoded_classes = label_encoder.classes_\n",
    "\n",
    "# Print the mapping\n",
    "print(\"Encoded Sentiment Values:\")\n",
    "for code, sentiment in enumerate(encoded_classes):\n",
    "    print(f\"Code {code} represents '{sentiment}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline model-Naive Bayes with Hyperparameter tuning using GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = data['lemmatized_tweet']  # Features\n",
    "y = data['emotion']          # Labels (contains multiclass labels)\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text data  using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "\n",
    "# Define a grid of hyperparameters to search\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0, 2.0],  # Smoothing parameter\n",
    "    'fit_prior': [True, False]  # Whether to learn class prior probabilities\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=naive_bayes, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform hyperparameter tuning on the training data\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_fit_prior = grid_search.best_params_['fit_prior']\n",
    "\n",
    "print(\"Best Alpha:\", best_alpha)\n",
    "print(\"Best Fit Prior:\", best_fit_prior)\n",
    "\n",
    "# Use the best hyperparameters to train the final model\n",
    "best_naive_bayes = MultinomialNB(alpha=best_alpha, fit_prior=best_fit_prior)\n",
    "best_naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Tuned Multinomial Naive Bayes Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model, a tuned Multinomial Naive Bayes classifier, demonstrates an accuracy of approximately 67.67% in the multiclass sentiment classification task. While it exhibits a relatively high precision (0.69) and recall (0.90) for the 'Positive' sentiment class, achieving an F1-score of 0.78, it struggles with the 'Neutral' and 'Negative' sentiment classes. For 'Neutral,' it obtains a lower precision (0.63) and recall (0.39), resulting in an F1-score of 0.48. The 'Negative' sentiment class poses the most challenge, with a precision of 0.67 and a recall of only 0.03, resulting in a minimal F1-score of 0.06. The confusion matrix reveals the model's difficulty in correctly classifying 'Neutral' and 'Negative' sentiments. Overall, while the baseline model shows promise in identifying 'Positive' sentiment, further improvements are needed to enhance its performance across all sentiment categories, especially 'Neutral' and 'Negative.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and labels (y)\n",
    "X = data['lemmatized_tweet']  # Features\n",
    "y = data['emotion']          # Labels (contains multiclass labels)\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize text data  using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Logistic Regression classifier\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logistic_regression.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the multiclass classification task using Logistic Regression, the model achieved an accuracy of approximately 68.85%, indicating its ability to correctly classify the sentiment of the provided text data. However, the precision and recall vary across sentiment classes. The model performs relatively well in identifying the 'Positive' sentiment class, with a precision of 0.71 and a recall of 0.87. On the other hand, it struggles with the 'Neutral' sentiment class, achieving a lower precision of 0.61 and a recall of 0.47, and it particularly struggles with the 'Negative' sentiment class, with a precision of 0.73 but a lower recall of 0.09. The F1-scores vary accordingly, with the 'Positive' class having the highest F1-score (0.78), while the 'Neutral' class has a lower F1-score (0.53). The confusion matrix shows the number of true positive, true negative, false positive, and false negative predictions for each sentiment class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the vectorizer on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "n_estimators = 100  # You can adjust the number of estimators (trees)\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "random_forest_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest classifier achieved an overall accuracy of approximately 69.3%. It performed well in identifying the neutral class (Label 1) with a high F1-Score of 0.78, indicating a good balance between precision and recall. However, its performance on the other classes (Label 0 and Label 2) was lower, particularly in terms of recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we conducted binary and multiclass sentiment analysis using various machine learning models to determine the best-performing model for the real-world problem of sentiment classification. \n",
    "\n",
    "Binary Sentiment Analysis:\n",
    "\n",
    "- Naive Bayes model served as the baseline and achieved an accuracy of 84.2%. While it performed well in identifying positive sentiments, it struggled with negative sentiments, with a very low recall.\n",
    "- Support Vector Machine (SVM) improved accuracy to 86.2% and showed better performance in identifying negative sentiments. However, it still had room for improvement in recall for class 0 (negative).\n",
    "- The Random Forest model outperformed the others, achieving an accuracy of 87.3%. It demonstrated balanced precision and recall for both positive and negative sentiments, making it the best choice for binary sentiment analysis\n",
    "\n",
    "Multiclass Sentiment Analysis:\n",
    "\n",
    "- Multinomial Naive Bayes  served as the baseline and achieved an accuracy of 67.7%. While it performed reasonably well for positive sentiments, it struggled with neutral and negative sentiments.\n",
    "- Logistic Regression model achieved an accuracy of 68.9% but faced challenges in correctly classifying negative sentiments.\n",
    "- Random Forest model achieved an accuracy of 69.3% and showed balanced performance across sentiments, making it the preferred choice for multiclass sentiment analysis.\n",
    "\n",
    "Overall, the Random Forest model consistently outperformed other models in both binary and multiclass sentiment analysis tasks. It provides a balanced approach to sentiment classification, which is vital for real-world applications where all sentiment categories are essential. The choice of this model is justified based on its performance and utility for solving the real-world problem of sentiment classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
