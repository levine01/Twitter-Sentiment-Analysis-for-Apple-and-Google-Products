{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset and preview first five rows\n",
    "data = pd.read_csv('judge-1377884607_tweet_product_company.csv', encoding='ISO-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting information of the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the Distribution of emotion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of instances for each sentiment label\n",
    "sentiment_counts = data['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(sentiment_counts)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values)\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Sentiment Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization, most people who tweeted dont have an emotion towards a brand or product and very few people we cant tell whether is positive, negative or have no emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Cleaning\n",
    "\n",
    "- Dropping unwanted columns\n",
    "- Handling missing values.\n",
    "- Clean text data by removing special characters, URLs, and hashtags.\n",
    "- Convert text to lowercase to ensure consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.1 Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping emotion_in_tweet_is_directed_at column since we wont be using it modelling\n",
    "columns_to_drop = ['emotion_in_tweet_is_directed_at']\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if the column has been dropped \n",
    "data.head()\n",
    "# the emotion in tweet is directed at column has been dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column has been dropped and we remain with the two columns that we will be using henceforth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.2 Handling mising values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if our dataset has missing values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the row with missing values\n",
    "# since we cannot impute text\n",
    "data = data.dropna(subset=['tweet_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking if the row with missing values has been dropped\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3 Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming'is_there_an_emotion_directed_at_a_brand_or_product'column to emotion to make it easy to work with\n",
    "data.rename(columns={'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previewing the first five rows to check if the column has been renamed.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'i cant tell' and No emotion toward brand or product' category since we will only be using the two sentiments.\n",
    "data = data[(data['emotion'] != \"I can't tell\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 'No emotion toward brand or product' as neutral\n",
    "#data['emotion'] = data['emotion'].replace({'No emotion toward brand or product': 'Neutral'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to see if 'i cant tell' category has been dropped and 'No emotion toward brand or product' has been replaced\n",
    "data.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.3 Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Ensure text is a string\n",
    "    text = str(text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove hashtags (including the # symbol)\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters and punctuation (except spaces)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "     # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the \"tweet_text\" column\n",
    "data['cleaned_tweet'] = data['tweet_text'].apply(clean_text)\n",
    "\n",
    "# Display the DataFrame with cleaned text\n",
    "print(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Tokenization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the \"tweet_text\" column\n",
    "data['tokenized_tweet'] = data['cleaned_tweet'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "# Display the DataFrame with tokenized text\n",
    "print(data[['cleaned_tweet', 'tokenized_tweet']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tokenized words into a single string for each document\n",
    "data['tokenized_tweet'] = data['tokenized_tweet'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform your tokenized text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['tokenized_tweet'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Label Encoding\n",
    "\n",
    "To convert emotion column (negative, neutral, positive) into numerical format 0,1,2 respectively for model training using LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criteria for 'Positive' and 'Negative'\n",
    "#positive_criteria = data['emotion'] == 'Positive emotion'\n",
    "#negative_criteria = data['emotion'] == 'Negative emotion'\n",
    "\n",
    "# Create a new column 'binary_label' with initial values set to 'Neutral'\n",
    "#data['binary_label'] = 'Neutral'\n",
    "\n",
    "# Update 'binary_label' based on the criteria\n",
    "#data.loc[positive_criteria, 'binary_label'] = 'Positive'\n",
    "#data.loc[negative_criteria, 'binary_label'] = 'Negative'\n",
    "\n",
    "# Now, the DataFrame should has a new column 'binary_label' with 'Positive' and 'Negative' labels \n",
    "# to use this column for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the label encoder\n",
    "#label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to the 'emotion' column\n",
    "#data['binary_label'] = label_encoder.fit_transform(data['emotion'])\n",
    "\n",
    "# Display the DataFrame with the encoded emotion labels\n",
    "#print(data[['emotion', 'binary_label']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in the 'emotion' column\n",
    "unique_emotions = data['emotion'].unique()\n",
    "print(\"Unique Emotions:\", unique_emotions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelling-Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Filtering - filter data to only have rows with 'Positive emotion' or 'Negative emotion' labels, effectively creating a binary classification dataset.\n",
    "- Splitting Data - split your filtered data into training and testing sets using the train_test_split function\n",
    "- Label Encoding: You encode the 'emotion' labels ('Positive emotion' and 'Negative emotion') into numerical values ('Positive' as 1 and 'Negative' as 0) using LabelEncoder. \n",
    "- TF-IDF Vectorization-use TF-IDF vectorization to convert your text data into numerical vectors. The TfidfVectorizer is used to represent each tweet as a vector of TF-IDF features.\n",
    "Naive Bayes Training-Initialize a Multinomial Naive Bayes classifier and train it on the TF-IDF vectors of the training data.\n",
    "-Making Predictions-Use the trained Naive Bayes model to make predictions on the test set.\n",
    "-Calculating Accuracy: You calculate the accuracy of the model's predictions on the test set using accuracy_score. Accuracy measures the proportion of correctly predicted instances.\n",
    "- Classification Report: You display a classification report, which includes precision, recall, and F1-score for each class ('Positive' and 'Negative'). This report provides a detailed overview of the model's performance.\n",
    "- Confusion Matrix-display a confusion matrix, which shows the number of true positive, true negative, false positive, and false negative predictions. This matrix is useful for assessing the model's performance on each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Baseline Model using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to include only 'Positive' and 'Negative' labels\n",
    "filtered_data = data[(data['emotion'] == 'Positive emotion') | (data['emotion'] == 'Negative emotion')]\n",
    "\n",
    "# Split the filtered data into features (X) and labels (y)\n",
    "X = filtered_data['tokenized_tweet']  # Features\n",
    "y = filtered_data['emotion']          # Labels (contains 'Positive' and 'Negative' classes)\n",
    "\n",
    "# Encode labels to numerical values (Positive: 1, Negative: 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectors for text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs well getting an accuracy of 84.2%  and correctly identifying 'Positive' tweets with high precision and recall, resulting in a high F1-score for class 1. However, it struggles to identify 'Negative' tweets, as indicated by the very low recall for class 0. The overall accuracy is somewhat inflated due to the class imbalance, where 'Positive' tweets dominate the dataset. Improving recall for class 0 may be a priority if better identification of 'Negative' sentiment is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model using Naive Bayes\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = naive_bayes.predict(X_valid_tfidf)\n",
    "\n",
    "# calculate accuracy\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_valid, y_pred_nb))\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_nb))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_valid, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided evaluation  shows that a Naive Bayes classifier achieved an accuracy of approximately 83.3% on the binary classification task. While it performed well in correctly predicting class 1 with high precision and recall, it struggled to identify class 0 instances, resulting in a low recall for class 0. The F1-score, a balanced metric, indicates a good overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1.3 Hyperparameter Tuning for Improved Model Performance using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a range of hyperparameters to search\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0],  # Range of alpha values to test\n",
    "    'fit_prior': [True, False],     # Whether to estimate class prior probabilities or not\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Get the best hyperparameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train a Naive Bayes model with the best hyperparameters\n",
    "best_nb_classifier = MultinomialNB(alpha=best_params['alpha'], fit_prior=best_params['fit_prior'])\n",
    "best_nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_best = best_nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Best Naive Bayes Accuracy:\", accuracy_best)\n",
    "\n",
    "# Display classification report for the tuned model\n",
    "print(\"Classification Report for Tuned Model:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "\n",
    "# Display confusion matrix for the tuned model\n",
    "print(\"Confusion Matrix for Tuned Model:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using hyperparameter tuning, the Naive Bayes classifier achieved an improved accuracy of approximately 86.7% on a binary classification task. It shows better performance in correctly predicting class 1 with high precision and recall, resulting in a high F1-score for class 1. However, it still faces challenges in identifying class 0 instances, leading to lower precision, recall, and F1-score for class 0. The overall weighted average F1-score indicates a good overall performance, but the model's effectiveness in classifying class 0 remains a concern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Machine(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data to include only 'Positive' and 'Negative' labels\n",
    "filtered_data = data[(data['emotion'] == 'Positive emotion') | (data['emotion'] == 'Negative emotion')]\n",
    "\n",
    "# Split the filtered data into features (X) and labels (y)\n",
    "X = filtered_data['tokenized_tweet']  # Features\n",
    "y = filtered_data['emotion']          # Labels (contains 'Positive' and 'Negative' classes)\n",
    "\n",
    "# Encode labels to numerical values (Positive: 1, Negative: 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectors for text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Support Vector Machine (SVM) classifier achieved an accuracy of approximately 86.2% on a binary classification task. The model exhibits good performance in correctly predicting class 1 with high precision and recall, resulting in a high F1-score for class 1. However, similar to the previous Naive Bayes model, it faces challenges in identifying class 0 instances, leading to lower precision, recall, and F1-score for class 0. The overall weighted average F1-score indicates a reasonably good overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best binary classification model is Naive Bayes Model with Hyperparameter Tuning which achieved the highest accuracy of approximately 86.8% after hyperparameter tuning.\n",
    "It's a strong candidate for this task because it's relatively simple, interpretable, and performs well on classifying sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = data['tokenized_tweet']  # Features (tweet text)\n",
    "y = data['emotion']      # Labels (sentiment classes)\n",
    "\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TF-IDF vectors for text data\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Multiclass Naive Bayes Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you have your text data in 'X' and labels in 'y'\n",
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the vectorizer on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "k = 5  # You can adjust the value of k\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "knn_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"KNN Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Encode labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the vectorizer on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data using the same vectorizer\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "n_estimators = 100  # You can adjust the number of estimators (trees)\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "\n",
    "# Fit the classifier on the training data\n",
    "random_forest_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = random_forest_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Random Forest Accuracy:\", accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Display confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest classifier achieved an overall accuracy of approximately 0.69 in the multiclass text classification task. It performed well in identifying the neutral class (Label 1) with a high F1-Score of 0.78, indicating a good balance between precision and recall. However, its performance on the other classes (Label 0 and Label 2) was lower, particularly in terms of recall. To enhance model performance, strategies like data collection for minority classes and hyperparameter tuning could be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
